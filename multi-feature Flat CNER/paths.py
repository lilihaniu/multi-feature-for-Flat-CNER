


yangjie_rich_pretrain_unigram_path = 'D:/BaiduNetdiskDownload/Ner/NeuralSegmentation/gigaword_chn.all.a2b.uni.ite50.vec'
yangjie_rich_pretrain_bigram_path = 'D:/BaiduNetdiskDownload/Ner/NeuralSegmentation/gigaword_chn.all.a2b.bi.ite50.vec'
yangjie_rich_pretrain_word_path = 'D:/BaiduNetdiskDownload/Ner/NeuralSegmentation/ctb.50d.vec'
yangjie_rich_pretrain_char_and_word_path = 'D:/BaiduNetdiskDownload/Ner/Flat_lattice embedding/word_char_mix.txt'
# lk_word_path = '/remote-home/xnli/data/pretrain/chinese/sgns.merge.word'
lk_word_path_2 = 'D:/BaiduNetdiskDownload/Ner/Flat_lattice embedding/sgns.merge.word/sgns.merge.word_2'



ontonote4ner_cn_path = '/remote-home/xnli/data/corpus/sequence_labelling/chinese_ner/OntoNote4NER'
msra_ner_cn_path = '/remote-home/xnli/data/corpus/sequence_labelling/chinese_ner/MSRANER'
resume_ner_path = 'D:/BaiduNetdiskDownload/Ner/Flat_lattice embedding/ResumeNER/ResumeNER'
weibo_ner_path = '/remote-home/xnli/data/corpus/sequence_labelling/chinese_ner/WeiboNER'



# yangjie_rich_pretrain_unigram_path = '{}/gigaword_chn.all.a2b.uni.ite50.vec'
# yangjie_rich_pretrain_bigram_path = '{}/gigaword_chn.all.a2b.bi.ite50.vec'
# yangjie_rich_pretrain_word_path = '{}/ctb.50d.vec'
#
# # this path is for the output of preprocessing
# yangjie_rich_pretrain_char_and_word_path = '{}/yangjie_word_char_mix.txt'
#
#
#
# ontonote4ner_cn_path = '{}/OntoNote4NER'
# msra_ner_cn_path = '{}/MSRANER'
# resume_ner_path = '{}/ResumeNER'
# weibo_ner_path = '{}/WeiboNER'